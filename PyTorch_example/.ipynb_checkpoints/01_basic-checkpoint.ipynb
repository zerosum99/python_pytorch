{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.16.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  함수 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_import_dotted_name, broadcast_tensors, btrifact, btrifact_with_info, btrisolve, \n",
      "btriunpack, cartesian_prod, chain_matmul, compiled_with_cxx11_abi, einsum, \n",
      "gesv, get_file_path, get_rng_state, initial_seed, is_storage, \n",
      "is_tensor, isfinite, isinf, load, lu, \n",
      "lu_unpack, manual_seed, meshgrid, norm, potrf, \n",
      "potri, potrs, prepare_multiprocessing_environment, pstrf, save, \n",
      "set_default_dtype, set_default_tensor_type, set_printoptions, set_rng_state, split, \n",
      "stft, tensordot, trtrs, typename, unique, \n",
      "unique_consecutive, "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in dir(torch) :\n",
    "        \n",
    "    if type(torch.__dict__[i]) == types.FunctionType :\n",
    "        count += 1\n",
    "        print(i, end=\", \")\n",
    "        if count % 5 == 0 :\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빌드인 함수 객체 목록 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.full) == types.BuiltinFunctionType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "builtin_function_or_method"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_adaptive_avg_pool2d, _baddbmm_mkl_, _batch_norm_impl_index, _cast_Byte, _cast_Char, \n",
      "_cast_Double, _cast_Float, _cast_Half, _cast_Int, _cast_Long, \n",
      "_cast_Short, _convolution, _convolution_nogroup, _copy_same_type_, _ctc_loss, \n",
      "_cudnn_ctc_loss, _cudnn_init_dropout_state, _cudnn_rnn, _cudnn_rnn_flatten_weight, _cufft_clear_plan_cache, \n",
      "_cufft_get_plan_cache_max_size, _cufft_get_plan_cache_size, _cufft_set_plan_cache_max_size, _debug_has_internal_overlap, _dim_arange, \n",
      "_dirichlet_grad, _embedding_bag, _empty_affine_quantized, _fft_with_size, _fused_dropout, \n",
      "_log_softmax, _log_softmax_backward_data, _lu_with_info, _masked_scale, _multinomial_alias_draw, \n",
      "_multinomial_alias_setup, _nnpack_available, _nnpack_spatial_convolution, _pack_padded_sequence, _pad_packed_sequence, \n",
      "_promote_types, _reshape_from_tensor, _s_copy_from, _s_where, _sample_dirichlet, \n",
      "_shape_as_tensor, _sobol_engine_draw, _sobol_engine_ff_, _sobol_engine_initialize_state_, _sobol_engine_scramble_, \n",
      "_softmax, _softmax_backward_data, _sparse_addmm, _sparse_mm, _sparse_sum, \n",
      "_standard_gamma, _standard_gamma_grad, _trilinear, _unique, _unique2, \n",
      "_weight_norm, _weight_norm_cuda_interface, abs, abs_, acos, \n",
      "acos_, adaptive_avg_pool1d, adaptive_max_pool1d, add, addbmm, \n",
      "addcdiv, addcmul, addmm, addmv, addmv_, \n",
      "addr, affine_grid_generator, all, allclose, alpha_dropout, \n",
      "alpha_dropout_, any, arange, argmax, argmin, \n",
      "argsort, as_strided, as_strided_, as_tensor, asin, \n",
      "asin_, atan, atan2, atan_, avg_pool1d, \n",
      "baddbmm, bartlett_window, batch_norm, batch_norm_backward_elemt, batch_norm_backward_reduce, \n",
      "batch_norm_elemt, batch_norm_gather_stats, batch_norm_stats, batch_norm_update_stats, bernoulli, \n",
      "bilinear, binary_cross_entropy_with_logits, bincount, blackman_window, bmm, \n",
      "cat, cdist, ceil, ceil_, celu, \n",
      "celu_, cholesky, cholesky_inverse, cholesky_solve, chunk, \n",
      "clamp, clamp_, clamp_max, clamp_max_, clamp_min, \n",
      "clamp_min_, clone, combinations, constant_pad_nd, conv1d, \n",
      "conv2d, conv3d, conv_tbc, conv_transpose1d, conv_transpose2d, \n",
      "conv_transpose3d, convolution, cos, cos_, cosh, \n",
      "cosh_, cosine_embedding_loss, cosine_similarity, cross, ctc_loss, \n",
      "cudnn_affine_grid_generator, cudnn_batch_norm, cudnn_convolution, cudnn_convolution_transpose, cudnn_grid_sampler, \n",
      "cudnn_is_acceptable, cumprod, cumsum, dequantize, det, \n",
      "detach, detach_, diag, diag_embed, diagflat, \n",
      "diagonal, digamma, dist, div, dot, \n",
      "dropout, dropout_, dsmm, eig, embedding, \n",
      "embedding_bag, embedding_renorm_, empty, empty_like, empty_strided, \n",
      "eq, equal, erf, erf_, erfc, \n",
      "erfc_, erfinv, exp, exp_, expm1, \n",
      "expm1_, eye, fbgemm_is_cpu_supported, fbgemm_linear_int8_weight, fbgemm_linear_quantize_weight, \n",
      "fbgemm_pack_quantized_matrix, feature_alpha_dropout, feature_alpha_dropout_, feature_dropout, feature_dropout_, \n",
      "fft, fill_, flatten, flip, floor, \n",
      "floor_, fmod, fork, frac, frac_, \n",
      "frobenius_norm, from_file, from_numpy, full, full_like, \n",
      "gather, ge, gels, geqrf, ger, \n",
      "get_default_dtype, get_device, get_num_threads, grid_sampler, grid_sampler_2d, \n",
      "grid_sampler_3d, group_norm, gru, gru_cell, gt, \n",
      "hamming_window, hann_window, hardshrink, hinge_embedding_loss, histc, \n",
      "hsmm, hspmm, ifft, import_ir_module, import_ir_module_from_buffer, \n",
      "index_add, index_copy, index_fill, index_put, index_put_, \n",
      "index_select, instance_norm, int_repr, inverse, irfft, \n",
      "is_anomaly_enabled, is_complex, is_distributed, is_floating_point, is_grad_enabled, \n",
      "is_nonzero, is_same_size, is_signed, isclose, isnan, \n",
      "kl_div, kthvalue, layer_norm, le, lerp, \n",
      "lgamma, linspace, log, log10, log10_, \n",
      "log1p, log1p_, log2, log2_, log_, \n",
      "log_softmax, logdet, logspace, logsumexp, lstm, \n",
      "lstm_cell, lt, lu_solve, margin_ranking_loss, masked_fill, \n",
      "masked_scatter, masked_select, matmul, matrix_power, matrix_rank, \n",
      "max, max_pool1d, max_pool1d_with_indices, max_pool2d, max_pool3d, \n",
      "mean, median, merge_type_from_type_comment, min, miopen_batch_norm, \n",
      "miopen_convolution, miopen_convolution_transpose, miopen_depthwise_convolution, mkldnn_convolution, mkldnn_convolution_backward_weights, \n",
      "mkldnn_max_pool2d, mkldnn_reshape, mm, mode, mul, \n",
      "multinomial, mv, mvlgamma, narrow, native_batch_norm, \n",
      "native_norm, ne, neg, neg_, nonzero, \n",
      "norm_except_dim, normal, nuclear_norm, numel, ones, \n",
      "ones_like, orgqr, ormqr, pairwise_distance, parse_ir, \n",
      "parse_type_comment, pdist, pin_memory, pinverse, pixel_shuffle, \n",
      "poisson, polygamma, pow, prelu, prod, \n",
      "q_scale, q_zero_point, qr, quantize_linear, quantized_gru_cell, \n",
      "quantized_lstm, quantized_lstm_cell, quantized_rnn_relu_cell, quantized_rnn_tanh_cell, rand, \n",
      "rand_like, randint, randint_like, randn, randn_like, \n",
      "randperm, range, reciprocal, reciprocal_, relu, \n",
      "relu_, remainder, renorm, repeat_interleave, reshape, \n",
      "resize_as_, rfft, rnn_relu, rnn_relu_cell, rnn_tanh, \n",
      "rnn_tanh_cell, roll, rot90, round, round_, \n",
      "rrelu, rrelu_, rsqrt, rsqrt_, rsub, \n",
      "s_copy_, s_native_addmm, s_native_addmm_, saddmm, scalar_tensor, \n",
      "scatter, scatter_add, select, selu, selu_, \n",
      "set_anomaly_enabled, set_flush_denormal, set_num_threads, sigmoid, sigmoid_, \n",
      "sign, sin, sin_, sinh, sinh_, \n",
      "slogdet, smm, softmax, solve, sort, \n",
      "sparse_coo_tensor, split_with_sizes, spmm, sqrt, sqrt_, \n",
      "squeeze, sspaddmm, stack, std, sub, \n",
      "sum, svd, symeig, t, take, \n",
      "tan, tan_, tanh, tanh_, tensor, \n",
      "threshold, threshold_, topk, trace, transpose, \n",
      "triangular_solve, tril, tril_indices, triplet_margin_loss, triu, \n",
      "triu_indices, trunc, trunc_, unbind, unsqueeze, \n",
      "var, wait, where, zero_, zeros, \n",
      "zeros_like, "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in dir(torch) :\n",
    "        \n",
    "    if type(torch.__dict__[i]) ==   types.BuiltinFunctionType  :\n",
    "        count += 1\n",
    "        print(i, end=\", \")\n",
    "        if count % 5 == 0 :\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모듈 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.utils)  == types.ModuleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_C, __config__, _jit_internal, _np, _ops, \n",
      "_six, _tensor_str, _thnn, _utils, _utils_internal, \n",
      "autograd, backends, cpp, cuda, distributed, \n",
      "distributions, functional, hub, jit, multiprocessing, \n",
      "nn, onnx, optim, os, platform, \n",
      "quasirandom, random, serialization, sparse, storage, \n",
      "sys, testing, torch, utils, version, \n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in dir(torch) :\n",
    "        \n",
    "    if type(torch.__dict__[i]) ==   types.ModuleType  :\n",
    "        count += 1\n",
    "        print(i, end=\", \")\n",
    "        if count % 5 == 0 :\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.finfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수와 빌트인 함수가 아닌 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG, AggregationType, Argument, ArgumentSpec, Block, \n",
      "BoolStorage, BoolTensor, BoolType, ByteStorage, ByteTensor, \n",
      "CharStorage, CharTensor, Code, CompilationUnit, CompleteArgumentSpec, \n",
      "DictType, DoubleStorage, DoubleTensor, ExecutionPlanState, ExtraFilesMap, \n",
      "FatalError, FileCheck, FloatStorage, FloatTensor, FloatType, \n",
      "Function, FunctionSchema, Future, Generator, Gradient, \n",
      "Graph, GraphExecutorState, HalfStorage, HalfStorageBase, HalfTensor, \n",
      "IODescriptor, IntStorage, IntTensor, IntType, JITException, \n",
      "ListType, LockingLogger, LoggerBase, LongStorage, LongTensor, \n",
      "Node, NoopLogger, NumberType, OptionalType, PyTorchFileReader, \n",
      "PyTorchFileWriter, SUM, ScriptMethod, ScriptModule, ShortStorage, \n",
      "ShortTensor, Size, Storage, StringType, Tensor, \n",
      "TensorType, TracingState, TupleType, Type, Use, \n",
      "Value, _StorageBase, __all__, __builtins__, __cached__, \n",
      "__doc__, __file__, __loader__, __name__, __package__, \n",
      "__path__, __spec__, __version__, _mkldnn, _storage_classes, \n",
      "_string_classes, _tensor_classes, bool, complex128, complex32, \n",
      "complex64, default_generator, device, double, dtype, \n",
      "enable_grad, finfo, float, float16, float32, \n",
      "float64, half, has_cuda, has_cudnn, has_lapack, \n",
      "has_mkl, has_mkldnn, has_openmp, iinfo, int, \n",
      "int16, int32, int64, int8, layout, \n",
      "long, name, no_grad, ops, qint8, \n",
      "set_grad_enabled, short, sparse_coo, strided, uint8, \n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in dir(torch) :\n",
    "        \n",
    "    if (type(torch.__dict__[i]) == types.FunctionType  or type(torch.__dict__[i]) ==  type(torch.full) or type(torch.__dict__[i]) ==   types.ModuleType ):\n",
    "        continue \n",
    "    else :\n",
    "        count += 1\n",
    "        print(i, end=\", \")\n",
    "        if count % 5 == 0 :\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 무작위 추출을 고정시킴 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x106fe2fb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base Tenseor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor.__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행과 열을 지정하면 텐서 객체를 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00],\n",
       "        [1.4013e-45, 0.0000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 자료형, 크기, 원소의 갯수(numel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.FloatTensor', torch.Size([2, 2]), 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(), x.size(), x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 차원 텐서 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.Tensor(4,3,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00],\n",
       "          [-2.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00],\n",
       "          [-2.0000e+00]],\n",
       "\n",
       "         [[ 1.5414e-44],\n",
       "          [ 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000e+00],\n",
       "          [ 0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00],\n",
       "          [ 0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00],\n",
       "          [ 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000e+00],\n",
       "          [ 0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00],\n",
       "          [ 0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00],\n",
       "          [ 0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000e+00],\n",
       "          [ 0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00],\n",
       "          [ 0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00],\n",
       "          [ 0.0000e+00]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 크기, 자료형, 원소의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3, 2, 1]), 'torch.FloatTensor', 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.size(), x2.type(), x2.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Other methods make to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]), tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]), tensor([[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.]]), tensor([[0.7576, 0.2793, 0.4031, 0.7347],\n",
       "         [0.0293, 0.7999, 0.3971, 0.7544],\n",
       "         [0.5695, 0.4388, 0.6387, 0.5247],\n",
       "         [0.6826, 0.3051, 0.4635, 0.4550]]), tensor([[-0.6970, -1.1608,  0.6995,  0.1991],\n",
       "         [ 0.8657,  0.2444, -0.6629,  0.8073],\n",
       "         [ 1.1017, -0.1759, -2.2456, -1.4465],\n",
       "         [ 0.0612, -0.6177, -0.7981, -0.1316]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(4,4), torch.ones(4,4), torch.eye(4,4),torch.rand(4,4), torch.randn(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1차원 배열 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.3000, 0.6000, 0.9000, 1.2000, 1.5000, 1.8000, 2.1000, 2.4000,\n",
       "        2.7000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = torch.arange(0, 3, step=0.3)\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.3000, 0.6000, 0.9000, 1.2000, 1.5000, 1.8000, 2.1000, 2.4000,\n",
       "        2.7000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[6,2],[3,4],[5,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 넘파이를 텐서로 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6],\n",
       "        [10, 11]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_test = np.array([[5,6],[10,11]])\n",
    "torch.from_numpy(numpy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Use to array function of Python make Tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4 = torch.Tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "x4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  슬라이스와 인덱스 검색 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[0:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5., 6.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[62., 72., 80.],\n",
       "        [ 4.,  5.,  6.],\n",
       "        [ 7.,  8.,  9.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[0:1,:] = torch.Tensor([62,72,80])\n",
    "x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 62.,  72.,  80.],\n",
       "        [200.,  78.,  89.],\n",
       "        [  7.,   8.,   9.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4[1] = torch.Tensor([200,78, 89])\n",
    "x4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서를 분리하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[62., 72., 80.]]),\n",
       " tensor([[200.,  78.,  89.]]),\n",
       " tensor([[7., 8., 9.]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x5 = torch.split(x4, 1,dim=0)\n",
    "x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서를 결합하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 62.,  72.,  80., 200.,  78.,  89.,   7.,   8.,   9.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(x5, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 62.,  72.,  80.],\n",
       "         [200.,  78.,  89.],\n",
       "         [  7.,   8.,   9.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(x5, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  마스킹 검색 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4212, -0.5107, -1.5727],\n",
       "         [-0.1232,  3.5870, -1.8313],\n",
       "         [ 1.5987, -1.2770,  0.3255]]), tensor([[1, 0, 0],\n",
       "         [1, 1, 1],\n",
       "         [0, 1, 0]], dtype=torch.uint8), tensor([-0.4212, -0.1232,  3.5870, -1.8313, -1.2770]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x6 = torch.randn(3,3)\n",
    "\n",
    "mask  = torch.ByteTensor([[1,0,0],[1,1,1],[0,1,0]])\n",
    "\n",
    "out = torch.masked_select(x6, mask)\n",
    "\n",
    "x6, mask, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reshaping on dimension of Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x7 = torch.zeros(2,2,1)\n",
    "x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x7.view(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x7.view(-1) # -1 = Automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x7.view(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x7.view(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.]]]), tensor([[0., 0.],\n",
       "         [0., 0.]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x8 = x7.squeeze()\n",
    "x7, x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x8.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10., 20., 30.],\n",
       "         [40., 50., 60.]]), tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x9 = torch.FloatTensor([[10,20,30],[40,50,60]])\n",
    "x10 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x9, x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[11., 22., 33.],\n",
       "         [44., 55., 66.]]), tensor([[11., 22., 33.],\n",
       "         [44., 55., 66.]]), tensor([[11., 22., 33.],\n",
       "         [44., 55., 66.]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x9  + x10, x9.add(x10), torch.add(x9, x10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -9., -18., -27.],\n",
       "         [-36., -45., -54.]]), tensor([[ 9., 18., 27.],\n",
       "         [36., 45., 54.]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x10.sub(x9), x9.sub(x10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16., 17., 18.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x10[1] + 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 10.,  40.,  90.],\n",
       "         [160., 250., 360.]]), tensor([[ 10.,  40.,  90.],\n",
       "         [160., 250., 360.]]), tensor([[ 10.,  40.,  90.],\n",
       "         [160., 250., 360.]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x9 * x10, x10.mul(x9), torch.mul(x10,x9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [40., 50., 60.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x10 * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Other Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 100.,  400.,  900.],\n",
       "         [1600., 2500., 3600.]]), tensor([[ 100.,  400.,  900.],\n",
       "         [1600., 2500., 3600.]]), tensor([[ 100.,  400.,  900.],\n",
       "         [1600., 2500., 3600.]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x9.pow(2), torch.pow(x9,2), x9 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1623, 4.4721, 5.4772],\n",
       "        [6.3246, 7.0711, 7.7460]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x9.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.6931, 1.0986],\n",
       "         [1.3863, 1.6094, 1.7918]]), tensor([[0.0000, 0.6931, 1.0986],\n",
       "         [1.3863, 1.6094, 1.7918]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x10.log(), torch.log(x10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 0.],\n",
       "         [1., 2., 0.]]), tensor([[ 3.3333,  6.6667, 10.0000],\n",
       "         [13.3333, 16.6667, 20.0000]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x9 % 3, x9 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(210.), tensor(60.))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x9.sum(), x9.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), torch.return_types.min(\n",
       " values=tensor([1., 2., 3.]),\n",
       " indices=tensor([0, 0, 0])), torch.return_types.min(\n",
       " values=tensor([1., 4.]),\n",
       " indices=tensor([0, 0])))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x10.min(), x10.min(0), x10.min(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([3., 6.]),\n",
       "indices=tensor([2, 2]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x10.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10., 20., 30.],\n",
       "         [40., 50., 60.]]), tensor([[10., 20., 30.],\n",
       "         [40., 50., 60.]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x9.abs(), x9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 10.,  20.,  30.],\n",
       "         [ -3.,   3., -10.]]), tensor([[10., 20., 30.],\n",
       "         [ 3.,  3., 10.]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x9[1] = torch.Tensor([-3,3,-10])\n",
    "x9, x9.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6.]), tensor([2, 2]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value, index = x10.max(dim = 1)\n",
    "value, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x10.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Matrix Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4791,  1.3790,  2.5286,  0.4107, -0.9880],\n",
       "         [-0.9081,  0.5423,  0.1103, -2.2590,  0.6067],\n",
       "         [-0.1383,  0.8310, -0.2477, -0.8029,  0.2366]]),\n",
       " tensor([[-0.5065,  0.0998, -0.6540,  0.7317, -1.4344],\n",
       "         [-0.5008,  0.1716, -0.1600,  0.2546,  0.1938],\n",
       "         [-2.5832,  0.8539,  1.2466,  0.5057,  0.9505],\n",
       "         [ 1.2966,  0.8738,  0.3434, -1.0703, -0.8743],\n",
       "         [-1.4648, -1.2629,  1.1220,  1.5663,  2.5581]]),\n",
       " tensor([[-1.1322, -0.0179,  0.1280],\n",
       "         [-0.5552, -0.4575, -1.9599],\n",
       "         [-1.1242, -1.5599,  1.4003],\n",
       "         [ 0.2963, -1.0901, -0.2380],\n",
       "         [ 0.6905,  0.4646, -0.7559]]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x11 = torch.randn(3,5)\n",
    "x12 = torch.randn(5,5)\n",
    "x13 = torch.randn(5,3)\n",
    "x11, x12, x13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.33094226"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.6200 * 1.1375  + 0.3436 * -0.9347 + -0.9112 * 1.3267 + -0.9952 *  -0.0336 + 0.7455 * 1.3210"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬간 계산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-4.9999,  3.9548,  2.2772, -0.7079,  0.4714],\n",
       "         [-3.9143, -2.6435,  0.5496,  2.8975,  5.0394],\n",
       "         [-1.0939, -1.0831, -0.3615,  1.2151,  1.4312]]),\n",
       " tensor([[-4.9999,  3.9548,  2.2772, -0.7079,  0.4714],\n",
       "         [-3.9143, -2.6435,  0.5496,  2.8975,  5.0394],\n",
       "         [-1.0939, -1.0831, -0.3615,  1.2151,  1.4312]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(x11,x12), x11.mm(x12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0210, -4.2816, -5.3899],\n",
       "        [ 9.6202, -0.3951,  0.9506],\n",
       "        [ 3.5947,  0.4194,  0.1054]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x11.mm(x12).mm(x13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.1442, -5.3929,  3.4447, 14.4192, -4.8815],\n",
       "        [-4.3821, 13.8420, 24.0462,  4.0808, -9.5197],\n",
       "        [-2.1178,  5.2721,  9.1094,  0.4444, -3.2721]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x11.mm(x12).mm(x13).mm(x11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬과 벡터 계산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.0501,  0.6842, -0.8003, -0.3738],\n",
       "         [ 1.4904, -1.2968, -0.3243,  0.3105],\n",
       "         [-0.3423,  0.6976,  1.4117,  2.1331]]),\n",
       " tensor([-0.1602,  0.3615,  0.3725, -0.3054]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x14 = torch.randn(3, 4)\n",
    "v = torch.randn(4)\n",
    "\n",
    "x14, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6250781"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " -0.4594 * 0.6623 + -1.1798 * 0.2916 +0.3812 * 0.0409+ -0.0064 *  -1.1908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.3919, -0.9233,  0.1815]), tensor([ 0.3919, -0.9233,  0.1815]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mv(x14,v), x14.mv(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  배치 행렬을 구하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function bmm:\n",
      "\n",
      "bmm(...)\n",
      "    bmm(batch1, batch2, out=None) -> Tensor\n",
      "    \n",
      "    Performs a batch matrix-matrix product of matrices stored in :attr:`batch1`\n",
      "    and :attr:`batch2`.\n",
      "    \n",
      "    :attr:`batch1` and :attr:`batch2` must be 3-D tensors each containing\n",
      "    the same number of matrices.\n",
      "    \n",
      "    If :attr:`batch1` is a :math:`(b \\times n \\times m)` tensor, :attr:`batch2` is a\n",
      "    :math:`(b \\times m \\times p)` tensor, :attr:`out` will be a\n",
      "    :math:`(b \\times n \\times p)` tensor.\n",
      "    \n",
      "    .. math::\n",
      "        \\text{out}_i = \\text{batch1}_i \\mathbin{@} \\text{batch2}_i\n",
      "    \n",
      "    .. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
      "              For broadcasting matrix products, see :func:`torch.matmul`.\n",
      "    \n",
      "    Args:\n",
      "        batch1 (Tensor): the first batch of matrices to be multiplied\n",
      "        batch2 (Tensor): the second batch of matrices to be multiplied\n",
      "        out (Tensor, optional): the output tensor\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> batch1 = torch.randn(10, 3, 4)\n",
      "        >>> batch2 = torch.randn(10, 4, 5)\n",
      "        >>> res = torch.bmm(batch1, batch2)\n",
      "        >>> res.size()\n",
      "        torch.Size([10, 3, 5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.bmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x15 = torch.randn(10,3,4)\n",
    "x16 = torch.randn(10,4,5)\n",
    "\n",
    "torch.bmm(x15, x16).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2415, -1.5127,  1.8725,  0.9361, -2.1943],\n",
       "         [ 1.8852,  1.5092, -1.3542, -0.4955,  1.3903],\n",
       "         [ 2.1632,  1.2025, -5.5970, -3.1589, -1.9429]],\n",
       "\n",
       "        [[-0.3138,  0.7091, -0.3345, -0.2515, -1.8707],\n",
       "         [-1.8431, -1.6969, -1.1658, -0.4207,  1.2151],\n",
       "         [-2.7380, -3.3490,  0.2056,  1.1899,  0.2361]],\n",
       "\n",
       "        [[-0.3279, -0.1757,  0.9764, -0.9167, -1.0516],\n",
       "         [-0.3682, -2.1802,  0.1170, -2.1677, -1.5388],\n",
       "         [ 2.2203,  4.7853,  3.3397, -1.1187, -1.8301]],\n",
       "\n",
       "        [[-1.3344,  1.4347,  2.0133,  2.6783,  5.2420],\n",
       "         [ 0.4516, -0.4568,  2.8375,  0.6817,  2.7954],\n",
       "         [ 1.7698, -1.7508, -3.9379,  0.7540, -0.3962]],\n",
       "\n",
       "        [[ 1.0369, -1.5131,  3.9795,  2.4460,  0.2701],\n",
       "         [ 1.4556,  1.9657,  0.4688, -1.4506, -0.6679],\n",
       "         [-0.5422,  2.4916, -4.2499, -0.5850, -1.4061]],\n",
       "\n",
       "        [[-1.5117, -3.9477,  0.2024, -1.9487, -2.6477],\n",
       "         [-1.1792,  1.5731, -1.2388, -0.4072, -1.8641],\n",
       "         [-0.0626, -0.6241, -0.9674,  0.3576, -2.0544]],\n",
       "\n",
       "        [[ 4.2340,  1.7616, -0.1110,  0.7026,  3.8383],\n",
       "         [-3.0023, -0.9605, -0.4626, -1.6328, -1.9774],\n",
       "         [ 3.2202,  2.4537,  1.0232,  0.8693,  1.5943]],\n",
       "\n",
       "        [[ 0.3976, -0.1240,  1.0175,  0.7411,  1.3517],\n",
       "         [-1.0686,  0.5056, -1.3917, -0.4075, -0.5391],\n",
       "         [ 0.4268, -0.0899, -0.2315,  0.1700, -0.4373]],\n",
       "\n",
       "        [[ 0.9802, -2.1276,  2.1641,  0.5908,  0.9301],\n",
       "         [-0.2713,  0.5547, -0.5866,  0.0551, -0.4539],\n",
       "         [ 0.7121,  1.5110, -0.9306, -0.4260,  0.6482]],\n",
       "\n",
       "        [[ 0.2663,  1.1518, -0.8572, -1.4829,  1.6050],\n",
       "         [ 1.4247, -1.0007,  0.0736,  2.7640,  1.1998],\n",
       "         [-0.4600, -0.0170,  0.6375, -0.6950, -0.0943]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(x15, x16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 닷 연산으로 처리 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.6870), tensor([[-0.6147,  1.0675],\n",
       "         [-0.2336,  0.8837]]), tensor([[-1.1205,  1.0734],\n",
       "         [-1.1730, -0.4771]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x17 = torch.randn(2,2)\n",
    "x18 = torch.randn(2,2)\n",
    "\n",
    "torch.dot(x17.view(-1), x18.view(-1)), x17, x18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3637122500000002"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.7038 *  -0.6295 + -1.6000 *  -1.0304 +  1.4366 * -0.0231 + -0.9917 * 0.1807"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6870)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(x17.view(-1), x18.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1185, 0.2355, 0.5599, 0.8966],\n",
       "         [0.2858, 0.1955, 0.1808, 0.2796],\n",
       "         [0.3273, 0.3835, 0.2156, 0.6563]]), tensor([[0.1185, 0.2858, 0.3273],\n",
       "         [0.2355, 0.1955, 0.3835],\n",
       "         [0.5599, 0.1808, 0.2156],\n",
       "         [0.8966, 0.2796, 0.6563]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x19  = torch.rand(3,4)\n",
    "\n",
    "x19, x19.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svd 분해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7507,  0.6519, -0.1066],\n",
       "         [-0.3093, -0.4895, -0.8153],\n",
       "         [-0.5837, -0.5791,  0.5691]]),\n",
       " tensor([1.4201, 0.3438, 0.1195]),\n",
       " tensor([[-0.2594, -0.7335, -0.4967],\n",
       "         [-0.3247, -0.4780,  0.2824],\n",
       "         [-0.4240,  0.4413, -0.7062],\n",
       "         [-0.8047,  0.1968,  0.4182]]),\n",
       " tensor([[0.1185, 0.2355, 0.5599, 0.8966],\n",
       "         [0.2858, 0.1955, 0.1808, 0.2796],\n",
       "         [0.3273, 0.3835, 0.2156, 0.6563]]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, s, v = torch.svd(x19)\n",
    "u, s, v, x19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.5914e-07)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(x19, torch.mm(torch.mm(u, torch.diag(s)), v.t()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tensor Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5041, 0.1733],\n",
       "        [0.2145, 0.6059]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x20 = torch.rand(2,2)\n",
    "x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x20  = torch.LongTensor([1,1])\n",
    "x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x20.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x20 = x20.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x20.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x20 = x20.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.DoubleTensor'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x20.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x20 = x20.byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.ByteTensor'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x20.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x20 = x20.cpu()\n",
    "x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x20 = x20.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x20.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x20 = torch.from_numpy(np.random.rand(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.DoubleTensor'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x20.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
