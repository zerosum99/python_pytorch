{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이토치 설명 자료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "context has already been set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fa5528cffd28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_start_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"spawn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pytorch-nlp\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36mset_start_method\u001b[1;34m(self, method, force)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_start_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_actual_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'context has already been set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_actual_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: context has already been set"
     ]
    }
   ],
   "source": [
    "# %load main.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"Provide example code to run ResNet-34 on Fashion MNIST dataset.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "import logging.handlers\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import torchvision.models\n",
    "import torchvision.transforms\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    \"\"\"Parse and return command line arguments.\n",
    "\n",
    "    Returns:\n",
    "        argparse.Namespace: The parsed arguments object.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=__doc__)\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int, default=64,\n",
    "                        help='The batch size to load the data. (default: 64)')\n",
    "    parser.add_argument('--num_workers', type=int, default=4,\n",
    "                        help=('The number of worker processes to use in '\n",
    "                              'loading the dataset. (default: 4)'))\n",
    "    parser.add_argument('--num_epochs', type=int, default=30,\n",
    "                        help=('The number of training epochs to run. (default:'\n",
    "                              '30)'))\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.1,\n",
    "                        help='The learning rate for SGD. (default: 0.1)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='The momentum for SGD. (default: 0.9)')\n",
    "    parser.add_argument('--checkpoint',\n",
    "                        help='The path of the checkpoint file to load')\n",
    "    parser.add_argument('--cuda', default=False, action='store_true',\n",
    "                        help='Use GPU if available.')\n",
    "\n",
    "    args = parser.parse_args(sys.argv[1:])\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_logger():\n",
    "    \"\"\"Prepare formatted logger to stream and file.\n",
    "\n",
    "    Returns:\n",
    "        logging.Logger: The logger object.\n",
    "    \"\"\"\n",
    "    # Prepare log directory.\n",
    "    try:\n",
    "        os.mkdir('logs')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Create logger and formatter.\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s %(message)s')\n",
    "\n",
    "    # Create and attach stream handler.\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "    # Create and attach file handler.\n",
    "    file_handler = logging.handlers.TimedRotatingFileHandler(\n",
    "        'logs/log.txt', when='d', encoding='utf-8')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "def get_data(batch_size, num_workers):\n",
    "    \"\"\"Download Fashion MNIST dataset and wrap with loaders.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of train, validation, and test data loaders.\n",
    "    \"\"\"\n",
    "    # Define data preprocessing.\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, ), (0.5, )),\n",
    "    ])\n",
    "\n",
    "    # Download and load the FashinMNIST data.\n",
    "    data = FashionMNIST(root='./data',\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=transform)\n",
    "    data_test = FashionMNIST(root='./data',\n",
    "                             train=False,\n",
    "                             download=True,\n",
    "                             transform=transform)\n",
    "\n",
    "    # Split training and validation data.\n",
    "    len_train = int(len(data) * 0.8)\n",
    "    len_val = len(data) - len_train\n",
    "    data_train, data_val = torch.utils.data.random_split(\n",
    "        data, [len_train, len_val])\n",
    "\n",
    "    # Wrap datasets with loaders.\n",
    "    data_train = torch.utils.data.DataLoader(\n",
    "        dataset=data_train,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True)\n",
    "    data_val = torch.utils.data.DataLoader(\n",
    "        dataset=data_val,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=False)\n",
    "    data_test = torch.utils.data.DataLoader(\n",
    "        dataset=data_test,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=False)\n",
    "\n",
    "    return data_train, data_val, data_test\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Return a ImageNet-pretrained ResNet-34 model, resized.\n",
    "\n",
    "    Returns:\n",
    "        (torch.nn.Module): The model, resized for the target task.\n",
    "    \"\"\"\n",
    "    # Load the pretrained model.\n",
    "    model = torchvision.models.resnet34(pretrained=True)\n",
    "\n",
    "    # Resize model for our task.\n",
    "    model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1,\n",
    "                                  bias=False)\n",
    "    model.avgpool = torch.nn.AvgPool2d(2)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer=None):\n",
    "    \"\"\"Load state from the given checkpoint file.\n",
    "\n",
    "    Args:\n",
    "        checkpoint (str): The path of the checkpoint file.\n",
    "        model (torch.nn.Module): The model to load state.\n",
    "        optimizer (torch.optim.Optimizer, optional): The optimizer to load\n",
    "               state.\n",
    "    \"\"\"\n",
    "    model_state_dict, optimizer_state_dict = torch.load(checkpoint)\n",
    "    model.load_state_dict(model_state_dict)\n",
    "\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "\n",
    "def train(model, loss_function, optimizer, data):\n",
    "    \"\"\"Train the model on the given data.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model.\n",
    "        loss_function (torch.nn.Module): The loss function to compare model\n",
    "            outputs with target values.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer algorithm to train the\n",
    "            model.\n",
    "        data (torch.utils.data.DataLoader): The data to train on.\n",
    "\n",
    "    Returns:\n",
    "        (float): The mean batch loss.\n",
    "    \"\"\"\n",
    "    loss_sum = 0\n",
    "\n",
    "    # Set the model in train mode.\n",
    "    model.train()\n",
    "\n",
    "    # Create progress bar.\n",
    "    progress_bar = tqdm.tqdm(total=len(data),\n",
    "                             unit='batch',\n",
    "                             desc='[train] batch loss: 0.000',\n",
    "                             leave=False)\n",
    "\n",
    "    # Loop through training batches.\n",
    "    for inputs, targets in data:\n",
    "\n",
    "        # Reset gradients.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Send data to GPU if CUDA is enabled.\n",
    "        if next(model.parameters()).is_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "        # Feed forward.\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        # Compute loss.\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Compute gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar.\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(\n",
    "            '[train] batch loss: {loss:.3f}'.format(loss=loss.item()))\n",
    "\n",
    "        # Accumulate loss sum.\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "    # Close progress bar.\n",
    "    progress_bar.close()\n",
    "\n",
    "    return loss_sum / len(data)\n",
    "\n",
    "\n",
    "def evaluate(model, data):\n",
    "    \"\"\"Evaluate the model on the given data.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model.\n",
    "        data (torch.utils.data.DataLoader): The data to train on.\n",
    "\n",
    "    Returns:\n",
    "        (float): The overall accuracy.\n",
    "    \"\"\"\n",
    "    n_targets = 0\n",
    "    n_correct_predictions = 0\n",
    "\n",
    "    # Set the model on evaluatio mode.\n",
    "    model.eval()\n",
    "\n",
    "    # Create progress bar.\n",
    "    progress_bar = tqdm.tqdm(total=len(data),\n",
    "                             unit='batch',\n",
    "                             desc='[evaluate] batch accuracy: 0.000',\n",
    "                             leave=False)\n",
    "\n",
    "    # Loop through validation batches.\n",
    "    for inputs, targets in data:\n",
    "\n",
    "        # Send data to GPU if CUDA is enabled.\n",
    "        if next(model.parameters()).is_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "        # Feed forward.\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        # Choose the class with maximum probability.\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        accuracy = (predictions == targets).sum().item() / len(targets)\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(\n",
    "            '[evaluate] batch accuracy: {accuracy:.3f}'.format(\n",
    "                accuracy=accuracy))\n",
    "\n",
    "        # Accumulate targets and correct predictions count.\n",
    "        n_targets += len(targets)\n",
    "        n_correct_predictions += (predictions == targets).sum().item()\n",
    "\n",
    "    # Close progress bar.\n",
    "    progress_bar.close()\n",
    "\n",
    "    return n_correct_predictions / n_targets\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Provide the main entrypoint.\n",
    "    \"\"\"\n",
    "    # Fix random seed.\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # Create checkpoint directory.\n",
    "    try:\n",
    "        os.mkdir('checkpoints')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Make preparations.\n",
    "    args = get_args()\n",
    "    logger = get_logger()\n",
    "    data_train, data_val, data_test = get_data(args.batch_size,\n",
    "                                               args.num_workers)\n",
    "    model = get_model()\n",
    "\n",
    "    # Log command arguments.\n",
    "    logger.info(' '.join(sys.argv))\n",
    "    logger.info(vars(args))\n",
    "\n",
    "    # Send the model to the GPU, if enabled and available.\n",
    "    if args.cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Create the loss function and optimizer.\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                lr=args.learning_rate,\n",
    "                                momentum=args.momentum)\n",
    "\n",
    "    # Load checkpoint, if given.\n",
    "    if args.checkpoint:\n",
    "        load_checkpoint(args.checkpoint, model, optimizer)\n",
    "\n",
    "    # Loop epochs.\n",
    "    for epoch in range(args.num_epochs):\n",
    "        logger.info(f'Epoch {epoch}:')\n",
    "\n",
    "        mean_loss = train(model, loss_function, optimizer, data_train)\n",
    "        logger.info(f'  - [training] mean loss: {mean_loss:.3f}')\n",
    "\n",
    "        accuracy = evaluate(model, data_val)\n",
    "        logger.info(f'  - [validation] accuracy: {accuracy:.3f}')\n",
    "\n",
    "        torch.save([model.state_dict(), optimizer.state_dict()],\n",
    "                   os.path.join('checkpoints', f'{epoch}.pth'))\n",
    "\n",
    "    # Run final evaluation on the test data.\n",
    "    logger.info('Test:')\n",
    "    accuracy = evaluate(model, data_test)\n",
    "    logger.info(f'  - [test] accuracy: {accuracy:.3f}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For displaying images, we will be using `matplotlib`, which works wonderfully even from within Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bob3rdnewbie.tistory.com/314\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
