{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\"\"\"Provide example code to run ResNet-34 on Fashion MNIST dataset.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "import logging.handlers\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import torchvision.models\n",
    "import torchvision.transforms\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    \"\"\"Parse and return command line arguments.\n",
    "\n",
    "    Returns:\n",
    "        argparse.Namespace: The parsed arguments object.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=__doc__)\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int, default=64,\n",
    "                        help='The batch size to load the data. (default: 64)')\n",
    "    parser.add_argument('--num_workers', type=int, default=4,\n",
    "                        help=('The number of worker processes to use in '\n",
    "                              'loading the dataset. (default: 4)'))\n",
    "    parser.add_argument('--num_epochs', type=int, default=30,\n",
    "                        help=('The number of training epochs to run. (default:'\n",
    "                              '30)'))\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.1,\n",
    "                        help='The learning rate for SGD. (default: 0.1)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='The momentum for SGD. (default: 0.9)')\n",
    "    parser.add_argument('--checkpoint',\n",
    "                        help='The path of the checkpoint file to load')\n",
    "    parser.add_argument('--cuda', default=False, action='store_true',\n",
    "                        help='Use GPU if available.')\n",
    "\n",
    "    args = parser.parse_args(sys.argv[1:])\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_logger():\n",
    "    \"\"\"Prepare formatted logger to stream and file.\n",
    "\n",
    "    Returns:\n",
    "        logging.Logger: The logger object.\n",
    "    \"\"\"\n",
    "    # Prepare log directory.\n",
    "    try:\n",
    "        os.mkdir('logs')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Create logger and formatter.\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s %(message)s')\n",
    "\n",
    "    # Create and attach stream handler.\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "    # Create and attach file handler.\n",
    "    file_handler = logging.handlers.TimedRotatingFileHandler(\n",
    "        'logs/log.txt', when='d', encoding='utf-8')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "def get_data(batch_size, num_workers):\n",
    "    \"\"\"Download Fashion MNIST dataset and wrap with loaders.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of train, validation, and test data loaders.\n",
    "    \"\"\"\n",
    "    # Define data preprocessing.\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, ), (0.5, )),\n",
    "    ])\n",
    "\n",
    "    # Download and load the FashinMNIST data.\n",
    "    data = FashionMNIST(root='./data',\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=transform)\n",
    "    data_test = FashionMNIST(root='./data',\n",
    "                             train=False,\n",
    "                             download=True,\n",
    "                             transform=transform)\n",
    "\n",
    "    # Split training and validation data.\n",
    "    len_train = int(len(data) * 0.8)\n",
    "    len_val = len(data) - len_train\n",
    "    data_train, data_val = torch.utils.data.random_split(\n",
    "        data, [len_train, len_val])\n",
    "\n",
    "    # Wrap datasets with loaders.\n",
    "    data_train = torch.utils.data.DataLoader(\n",
    "        dataset=data_train,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True)\n",
    "    data_val = torch.utils.data.DataLoader(\n",
    "        dataset=data_val,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=False)\n",
    "    data_test = torch.utils.data.DataLoader(\n",
    "        dataset=data_test,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=False)\n",
    "\n",
    "    return data_train, data_val, data_test\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Return a ImageNet-pretrained ResNet-34 model, resized.\n",
    "\n",
    "    Returns:\n",
    "        (torch.nn.Module): The model, resized for the target task.\n",
    "    \"\"\"\n",
    "    # Load the pretrained model.\n",
    "    model = torchvision.models.resnet34(pretrained=True)\n",
    "\n",
    "    # Resize model for our task.\n",
    "    model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1,\n",
    "                                  bias=False)\n",
    "    model.avgpool = torch.nn.AvgPool2d(2)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer=None):\n",
    "    \"\"\"Load state from the given checkpoint file.\n",
    "\n",
    "    Args:\n",
    "        checkpoint (str): The path of the checkpoint file.\n",
    "        model (torch.nn.Module): The model to load state.\n",
    "        optimizer (torch.optim.Optimizer, optional): The optimizer to load\n",
    "               state.\n",
    "    \"\"\"\n",
    "    model_state_dict, optimizer_state_dict = torch.load(checkpoint)\n",
    "    model.load_state_dict(model_state_dict)\n",
    "\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "\n",
    "def train(model, loss_function, optimizer, data):\n",
    "    \"\"\"Train the model on the given data.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model.\n",
    "        loss_function (torch.nn.Module): The loss function to compare model\n",
    "            outputs with target values.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer algorithm to train the\n",
    "            model.\n",
    "        data (torch.utils.data.DataLoader): The data to train on.\n",
    "\n",
    "    Returns:\n",
    "        (float): The mean batch loss.\n",
    "    \"\"\"\n",
    "    loss_sum = 0\n",
    "\n",
    "    # Set the model in train mode.\n",
    "    model.train()\n",
    "\n",
    "    # Create progress bar.\n",
    "    progress_bar = tqdm.tqdm(total=len(data),\n",
    "                             unit='batch',\n",
    "                             desc='[train] batch loss: 0.000',\n",
    "                             leave=False)\n",
    "\n",
    "    # Loop through training batches.\n",
    "    for inputs, targets in data:\n",
    "\n",
    "        # Reset gradients.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Send data to GPU if CUDA is enabled.\n",
    "        if next(model.parameters()).is_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "        # Feed forward.\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        # Compute loss.\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Compute gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar.\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(\n",
    "            '[train] batch loss: {loss:.3f}'.format(loss=loss.item()))\n",
    "\n",
    "        # Accumulate loss sum.\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "    # Close progress bar.\n",
    "    progress_bar.close()\n",
    "\n",
    "    return loss_sum / len(data)\n",
    "\n",
    "\n",
    "def evaluate(model, data):\n",
    "    \"\"\"Evaluate the model on the given data.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model.\n",
    "        data (torch.utils.data.DataLoader): The data to train on.\n",
    "\n",
    "    Returns:\n",
    "        (float): The overall accuracy.\n",
    "    \"\"\"\n",
    "    n_targets = 0\n",
    "    n_correct_predictions = 0\n",
    "\n",
    "    # Set the model on evaluatio mode.\n",
    "    model.eval()\n",
    "\n",
    "    # Create progress bar.\n",
    "    progress_bar = tqdm.tqdm(total=len(data),\n",
    "                             unit='batch',\n",
    "                             desc='[evaluate] batch accuracy: 0.000',\n",
    "                             leave=False)\n",
    "\n",
    "    # Loop through validation batches.\n",
    "    for inputs, targets in data:\n",
    "\n",
    "        # Send data to GPU if CUDA is enabled.\n",
    "        if next(model.parameters()).is_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "        # Feed forward.\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        # Choose the class with maximum probability.\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        accuracy = (predictions == targets).sum().item() / len(targets)\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(\n",
    "            '[evaluate] batch accuracy: {accuracy:.3f}'.format(\n",
    "                accuracy=accuracy))\n",
    "\n",
    "        # Accumulate targets and correct predictions count.\n",
    "        n_targets += len(targets)\n",
    "        n_correct_predictions += (predictions == targets).sum().item()\n",
    "\n",
    "    # Close progress bar.\n",
    "    progress_bar.close()\n",
    "\n",
    "    return n_correct_predictions / n_targets\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Provide the main entrypoint.\n",
    "    \"\"\"\n",
    "    # Fix random seed.\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # Create checkpoint directory.\n",
    "    try:\n",
    "        os.mkdir('checkpoints')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Make preparations.\n",
    "    args = get_args()\n",
    "    logger = get_logger()\n",
    "    data_train, data_val, data_test = get_data(args.batch_size,\n",
    "                                               args.num_workers)\n",
    "    model = get_model()\n",
    "\n",
    "    # Log command arguments.\n",
    "    logger.info(' '.join(sys.argv))\n",
    "    logger.info(vars(args))\n",
    "\n",
    "    # Send the model to the GPU, if enabled and available.\n",
    "    if args.cuda:\n",
    "        print(\"\"\" cuda model \"\"\")\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Create the loss function and optimizer.\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                lr=args.learning_rate,\n",
    "                                momentum=args.momentum)\n",
    "\n",
    "    # Load checkpoint, if given.\n",
    "    if args.checkpoint:\n",
    "        load_checkpoint(args.checkpoint, model, optimizer)\n",
    "\n",
    "    # Loop epochs.\n",
    "    for epoch in range(args.num_epochs):\n",
    "        logger.info(f'Epoch {epoch}:')\n",
    "\n",
    "        mean_loss = train(model, loss_function, optimizer, data_train)\n",
    "        logger.info(f'  - [training] mean loss: {mean_loss:.3f}')\n",
    "\n",
    "        accuracy = evaluate(model, data_val)\n",
    "        logger.info(f'  - [validation] accuracy: {accuracy:.3f}')\n",
    "\n",
    "        torch.save([model.state_dict(), optimizer.state_dict()],\n",
    "                   os.path.join('checkpoints', f'{epoch}.pth'))\n",
    "\n",
    "    # Run final evaluation on the test data.\n",
    "    logger.info('Test:')\n",
    "    accuracy = evaluate(model, data_test)\n",
    "    logger.info(f'  - [test] accuracy: {accuracy:.3f}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-30 22:43:27,547 main.py --cuda\n",
      "2018-09-30 22:43:27,547 main.py --cuda\n",
      "2018-09-30 22:43:27,547 main.py --cuda\n",
      "2018-09-30 22:43:27,561 {'batch_size': 64, 'num_workers': 4, 'num_epochs': 30, 'learning_rate': 0.1, 'momentum': 0.9, 'checkpoint': None, 'cuda': True}\n",
      "2018-09-30 22:43:27,561 {'batch_size': 64, 'num_workers': 4, 'num_epochs': 30, 'learning_rate': 0.1, 'momentum': 0.9, 'checkpoint': None, 'cuda': True}\n",
      "2018-09-30 22:43:27,561 {'batch_size': 64, 'num_workers': 4, 'num_epochs': 30, 'learning_rate': 0.1, 'momentum': 0.9, 'checkpoint': None, 'cuda': True}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cuda model \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-30 22:43:27,747 Epoch 0:\n",
      "2018-09-30 22:43:27,747 Epoch 0:\n",
      "2018-09-30 22:43:27,747 Epoch 0:\n",
      "\n",
      "\n",
      "[train] batch loss: 0.000:   0%|          | 0/750 [00:00<?, ?batch/s]"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module '__main__' has no attribute '__spec__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\GitHub\\python_pytorch\\pytorch_nlp\\sample_pytorch_project-master\\main.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\python_pytorch\\pytorch_nlp\\sample_pytorch_project-master\\main.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch {epoch}:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0mmean_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'  - [training] mean loss: {mean_loss:.3f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\python_pytorch\\pytorch_nlp\\sample_pytorch_project-master\\main.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, loss_function, optimizer, data)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;31m# Loop through training batches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;31m# Reset gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch-nlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch-nlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# ensure that the worker exits on process exit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0m_update_worker_pids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch-nlp\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch-nlp\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch-nlp\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch-nlp\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mprep_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_preparation_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# read end of pipe will be \"stolen\" by the child process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch-nlp\\lib\\multiprocessing\\spawn.py\u001b[0m in \u001b[0;36mget_preparation_data\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;31m# or through direct execution (or to leave it alone entirely)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mmain_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0mmain_mod_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__spec__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmain_mod_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'init_main_from_name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_mod_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '__main__' has no attribute '__spec__'"
     ]
    }
   ],
   "source": [
    "%run main.py --cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
