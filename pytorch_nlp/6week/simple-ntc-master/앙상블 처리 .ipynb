{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mREADME.md\u001b[m\u001b[m*               \u001b[31mdata_loader.py\u001b[m\u001b[m*          \u001b[31mtrain.py\u001b[m\u001b[m*\r\n",
      "Untitled.ipynb           \u001b[31mget_confusion_matrix.py\u001b[m\u001b[m* \u001b[31mutils.py\u001b[m\u001b[m*\r\n",
      "\u001b[31mclassify.py\u001b[m\u001b[m*             \u001b[34mmodels\u001b[m\u001b[m/\r\n",
      "\u001b[34mdata\u001b[m\u001b[m/                    \u001b[34msimple_ntc\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load classify.py\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext import data\n",
    "\n",
    "from simple_ntc.rnn import RNNClassifier\n",
    "from simple_ntc.cnn import CNNClassifier\n",
    "\n",
    "\n",
    "def define_argparser():\n",
    "    '''\n",
    "    Define argument parser to take inference using pre-trained model.\n",
    "    '''\n",
    "    p = argparse.ArgumentParser()\n",
    "\n",
    "    p.add_argument('--model', required=True)\n",
    "    p.add_argument('--gpu_id', type=int, default=-1)\n",
    "    p.add_argument('--batch_size', type=int, default=256)\n",
    "    p.add_argument('--top_k', type=int, default=1)\n",
    "\n",
    "    config = p.parse_args()\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def read_text():\n",
    "    '''\n",
    "    Read text from standard input for inference.\n",
    "    '''\n",
    "    lines = []\n",
    "\n",
    "    for line in sys.stdin:\n",
    "        if line.strip() != '':\n",
    "            lines += [line.strip().split(' ')]\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def define_field():\n",
    "    '''\n",
    "    To avoid use DataLoader class, just declare dummy fields. \n",
    "    With those fields, we can retore mapping table between words and indice.\n",
    "    '''\n",
    "    return (data.Field(use_vocab=True, \n",
    "                       batch_first=True, \n",
    "                       include_lengths=False\n",
    "                       ),\n",
    "            data.Field(sequential=False, \n",
    "                       use_vocab=True,\n",
    "                       unk_token=None\n",
    "                       )\n",
    "            )\n",
    "\n",
    "\n",
    "def main(config):\n",
    "    saved_data = torch.load(config.model, map_location='cpu' if config.gpu_id < 0 else 'cuda:%d' % config.gpu_id)\n",
    "\n",
    "    train_config = saved_data['config']\n",
    "    rnn_best = saved_data['rnn']\n",
    "    cnn_best = saved_data['cnn']\n",
    "    vocab = saved_data['vocab']\n",
    "    classes = saved_data['classes']\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    text_field, label_field = define_field()\n",
    "    text_field.vocab = vocab\n",
    "    label_field.vocab = classes\n",
    "\n",
    "    lines = read_text()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Converts string to list of index.\n",
    "        x = text_field.numericalize(text_field.pad(lines),\n",
    "                                    device='cuda:%d' % config.gpu_id if config.gpu_id >= 0 else 'cpu'\n",
    "                                    )\n",
    "\n",
    "        ensemble = []\n",
    "        if rnn_best is not None:\n",
    "            # Declare model and load pre-trained weights.\n",
    "            model = RNNClassifier(input_size=vocab_size,\n",
    "                                  word_vec_dim=train_config.word_vec_dim,\n",
    "                                  hidden_size=train_config.hidden_size,\n",
    "                                  n_classes=n_classes,\n",
    "                                  n_layers=train_config.n_layers,\n",
    "                                  dropout_p=train_config.dropout\n",
    "                                  )\n",
    "            model.load_state_dict(rnn_best['model'])\n",
    "            ensemble += [model]\n",
    "        if cnn_best is not None:\n",
    "            # Declare model and load pre-trained weights.\n",
    "            model = CNNClassifier(input_size=vocab_size,\n",
    "                                  word_vec_dim=train_config.word_vec_dim,\n",
    "                                  n_classes=n_classes,\n",
    "                                  dropout_p=train_config.dropout,\n",
    "                                  window_sizes=train_config.window_sizes,\n",
    "                                  n_filters=train_config.n_filters\n",
    "                                  )\n",
    "            model.load_state_dict(cnn_best['model'])\n",
    "            ensemble += [model]\n",
    "\n",
    "        y_hats = []\n",
    "        # Get prediction with iteration on ensemble.\n",
    "        for model in ensemble:\n",
    "            if config.gpu_id >= 0:\n",
    "                model.cuda(config.gpu_id)\n",
    "            # Don't forget turn-on evaluation mode.\n",
    "            model.eval()\n",
    "\n",
    "            y_hat = []\n",
    "            for idx in range(0, len(lines), config.batch_size):\n",
    "                y_hat += [model(x[idx:idx + config.batch_size])]\n",
    "            # Concatenate the mini-batch wise result\n",
    "            y_hat = torch.cat(y_hat, dim=0)\n",
    "            # |y_hat| = (len(lines), n_classes)\n",
    "\n",
    "            y_hats += [y_hat]\n",
    "        # Merge to one tensor for ensemble result and make probability from log-prob.\n",
    "        y_hats = torch.stack(y_hats).exp()\n",
    "        # |y_hats| = (len(ensemble), len(lines), n_classes)\n",
    "        y_hats = y_hats.sum(dim=0) / len(ensemble) # Get average\n",
    "        # |y_hats| = (len(lines), n_classes)\n",
    "\n",
    "        probs, indice = y_hats.cpu().topk(config.top_k)\n",
    "\n",
    "        for i in range(len(lines)):\n",
    "            sys.stdout.write('%s\\t%s\\n' % (' '.join([classes.itos[indice[i][j]] for j in range(config.top_k)]), \n",
    "                             ' '.join(lines[i]))\n",
    "                             )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = define_argparser()\n",
    "    main(config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
